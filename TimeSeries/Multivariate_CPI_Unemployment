########################################################
# Advanced Time Series Analysis                        #
# Analysing Inlation, Unemployment and Interest Rates  #
# Oriol Eixarch Mej√≠as r0872954 12/10/2025             #
########################################################

#   0 Preparation and Set Up
##  0.1 Loading packages
packages <- c("quantmod","dplyr","readxl","lubridate","CADFtest","forecast","zoo",'pander','urca','vars')
needed <- setdiff(packages,rownames(installed.packages()))
if(length(needed)) install.packages(needed, dependencies=TRUE)
invisible(lapply(packages,library,character.only=TRUE))

##  0.2 Utilities: Custom made functions
### 0.2.1 Styled tables for CADF tests including coefficients
panderOptions('table.split.table', Inf)
pander_display_test <- function(test){
  mymodel <- summary(test)$model
  my_coeff <- mymodel$coefficients
  colnames(my_coeff)
  coeff_table <- as.data.frame(my_coeff)
  coeff_table[,4] <- ifelse(coeff_table[,4] < 0.01, 
                            paste0(round(coeff_table[,4], 7), " ***"),
                            ifelse(coeff_table[,4] < 0.05,
                                   paste0(round(coeff_table[,4], 7), " **"),
                                   ifelse(coeff_table[,4] < 0.1,
                                          paste0(round(coeff_table[,4], 7), " *"),
                                          round(coeff_table[,4], 7))))
  coeff_table$Estimator <- rownames(coeff_table)
  coeff_table <- coeff_table %>% relocate(last_col(), .before=1)
  rownames(coeff_table) <- NULL
  pander(test)
  pander(coeff_table, caption="Test's Coefficients Significance")
}

### 0.2.2 Simulating "CheckResiduals" function from Forecast using in-course materials
residual_plots <- function(residuals,model_name, lags=48){
  bt <- Box.test(residuals,lag=lags,type='Ljung-Box')
  layout(matrix(c(1,2,3,3),nrow=2,byrow=TRUE))
  par(mar=c(4,2,3,1), oma=c(1,1,1,1))
  hist(residuals, xlab='Value of Residuals', main=paste("Histogram of the",model_name,"Residuals", sep=' '))
  grid()
  acf(residuals, main=paste("Autocorrelogram",model_name,"Residuals", sep=' '),
      ylab='',xaxt='n',xlab='Lag (Months)', lag.max=lags)
  axis(1, at=seq(0,lags,by=6)/12, labels=seq(0,lags,by=6))
  plot(residuals, ylab='Residuals',xlab='Time Period (Year and Months)', 
       main=paste("Residuals of a",model_name,"Model", sep=' '))
  grid()
  return(pander(bt))
  layout(1)
}

### 0.2.3 MAPE Computation
MAPE_comp <- function(original_ts,errors, horizon=1, multi=FALSE){
  if (multi){
    S <- round(nrow(original_ts)*0.80)
  } else {
    S <- round(length(original_ts)*0.80)
  }
  h <- horizon
  start_date <- time(original_ts)[S + h]
  actual_serie <- window(original_ts, start=start_date)
  if (multi){
    MAPE <- round(colMeans(abs(errors/actual_serie)),3)
  } else {
    MAPE <- round(mean(abs(errors/actual_serie)),3)
  }
  return(MAPE)
}


### 0.2.4 Multivariate Expanding Errors computation and optional plotting 
expanding_errors_multi <- function(series,VAR_order=2,coint_equations=1,horizon=1, plot=FALSE){
  f <- frequency(series)
  time_index <- time(series)
  nombres <- colnames(series)
  N <- nrow(series)
  S <- round(N * 0.80)
  h <- horizon
  n_steps <- (N - h) - S + 1
  forecast_roll <- matrix(NA, nrow=n_steps, ncol=ncol(series))
  upper_roll <- matrix(NA, nrow=n_steps, ncol=ncol(series))
  lower_roll <- matrix(NA, nrow=n_steps, ncol=ncol(series))
  colnames(forecast_roll) <- colnames(upper_roll) <- colnames(lower_roll) <- colnames(series)
  step_idx <- 0
  for (i in S:(N - h)) {
    step_idx <- step_idx + 1
    end_time <- time_index[i]
    muestra <- window(series, end=end_time)
    trace_test <- ca.jo(muestra, type="trace",K=VAR_order,ecdet="const",spec="transitory")
    vecm_var <- vec2var(trace_test, r=coint_equations)
    forec <- predict(vecm_var, n.ahead = h)
    names(forec$fcst) <- nombres
    for (j in 1:ncol(series)) {
      columna <- nombres[j]
      forecast_roll[step_idx,j] <- forec$fcst[[columna]][h,"fcst"]
      upper_roll[step_idx,j] <- forec$fcst[[columna]][h,"upper"]
      lower_roll[step_idx,j] <- forec$fcst[[columna]][h,"lower"]
    }
  }
  actual <- series[(S + h):N, , drop=FALSE]
  errors <- actual - forecast_roll
  if (plot){
    par(mfrow=c(ncol(series),1))
    par(mar=c(2,2,2,1), oma=c(1,1,1,1))
    start_date <- time_index[S + h]
    for (j in 1:ncol(series)){
      actual_ts <- ts(actual[,j], start=start_date,frequency=f)
      forecasted_ts <- ts(forecast_roll[,j], start=start_date, frequency=f)
      upper_ts <- ts(upper_roll[,j], start=start_date, frequency=f)
      lower_ts <- ts(lower_roll[,j], start=start_date, frequency=f)
      plot.ts(actual_ts, col="royalblue", lwd=2, ylim=range(upper_ts,lower_ts,actual_ts,forecasted_ts),
              main=paste("Actual vs Rolling VECM forecast:", nombres[j]), ylab=nombres[j],xlab="")
      lines(forecasted_ts, col="red", lwd = 2)
      lines(upper_ts, col="orange", lty=3, lwd=2)
      lines(lower_ts, col="orange", lty=3, lwd=2)
      legend("topleft",legend = c("Actual", "Forecast", "Bounds"),
             col=c("royalblue", "red", "orange"),lty=c(1,1,3),lwd=c(2,2,2),cex=0.7)
      grid()
    }
    par(mfrow=c(1, 1))
  }
  return(errors)
}

### 0.2.5 Deseasonalizing TS for multivariate analysis. 
# Using cycle to get the number of the month and factor to treat is as dummy, otherwise would be anumeric variable from 1-12 a sort of trend.
deseason <- function(Serie){
  season_reg <- lm(as.numeric(Serie) ~ factor(cycle(Serie)))
  seasonality_ts <- ts(fitted(season_reg), start=start(Serie), frequency=frequency(Serie))
  deseasonalized <- Serie - seasonality_ts
  return(deseasonalized)
}

##  0.3 Getting raw data
# Harmonized Index of Consumer Prices (FRED via EUROSTAT): All Items for the Euro Area 19
# 3-Month or 90-Day Rates and Yields (FRED via OECD): Interbank Rates for the Euro Area 19
# Monthly Unemployment in the EU area (19 countries)
getSymbols(c("CP0000EZ19M086NEST","IR3TIB01EZM156N"),src='FRED')
path  <-  "C:/Users/User/OneDrive/UNI/MASTER/Adv Time Series Analysis/Assignment/"
path <- paste0(path,"Unemployment_monthly_2000_2025.xlsx")
EU_unemployment <- read_excel(path, sheet='Data_I_pct')
EU_unemployment$TIME <- ym(EU_unemployment$TIME)
str(CP0000EZ19M086NEST)
str(IR3TIB01EZM156N)
str(EU_unemployment)

##  0.4 Cleaning data
max_date_available <- min(max(index(CP0000EZ19M086NEST)),
                         max(index(IR3TIB01EZM156N)),
                         max(EU_unemployment$TIME))
txt_filter <- paste0('2000-01-01','/',max_date_available)
Prices_2000_2025 <- CP0000EZ19M086NEST[txt_filter]
colnames(Prices_2000_2025) <- 'ConsumerPriceIndex'
Rates_2000_2025 <- IR3TIB01EZM156N[txt_filter]
colnames(Rates_2000_2025) <- 'InterbankRates'
EU_unemployment_2000_2025 <- EU_unemployment %>% filter(TIME >= ymd('2000-01-01'), TIME <= max_date_available)

##  0.5 Single Data frame 2000/01-2025/08 and R Time Series
Data <- data.frame(
  Date = EU_unemployment_2000_2025$TIME,
  Prices = round(as.numeric(Prices_2000_2025$ConsumerPriceIndex),1),
  Rates = round(as.numeric(Rates_2000_2025$InterbankRates),1),
  Unemployment = round(as.numeric(EU_unemployment_2000_2025$`Euro area`),1),
  row.names = NULL
)

Prices_ts <- ts(data=Data$Prices, start=c(2000,1), frequency=12)
Rates_ts <- ts(data=Data$Rates, start=c(2000,1), frequency=12)
Unemployment_ts <- ts(data=Data$Unemployment, start=c(2000,1), frequency=12)

#   2) Multivariate Serie Analysis
par(mfrow=c(3,1))
par(mar=c(3,4,2,1), oma=c(1,1,1,0))

##  2.1 Visualization
plot(Prices_ts,col='blue',lty=1,lwd=3,xlab='',ylab='CPI Index (Bae 2015)',
     main="Consumer Price Index (Base 2015) monthly Evolution in the EU Area 2000-2025")
grid()
plot(Rates_ts,col='darkgreen',lty=1,lwd=3,xlab='',ylab='Percentage Points (%)',
     main="Interbank Rates monthly Evolution in the EU Area 2000-2025 (%)")
grid()
plot(Unemployment_ts,col='orange',lty=1,lwd=3,xlab='',ylab='Percentage Points (%)',
     main="Unemployment Rate monthly Evolution in the EU Area 2000-2025 (%)")
grid()
par(mfrow=c(1,1))

##  2.2 Testing 
### 2.2.1 Series for unit root (ADF)
Prices_ts_log <- log(Prices_ts)
test_logcpi <- CADFtest(Prices_ts_log, type='trend', criterion='BIC', max.lag.y=round(sqrt(length(Rates_ts))))
pander_display_test(test_logcpi)
# Our serie logCPI is not stationary and has a stochastic trend.

test_rates <- CADFtest(Rates_ts, type='trend', criterion='BIC', max.lag.y=round(sqrt(length(Rates_ts))))
pander_display_test(test_rates)
test_rates <- CADFtest(Rates_ts, type='drift', criterion='BIC', max.lag.y=round(sqrt(length(Rates_ts))))
pander_display_test(test_rates)
test_rates <- CADFtest(Rates_ts, type='none', criterion='BIC', max.lag.y=round(sqrt(length(Rates_ts))))
pander_display_test(test_rates)
# It seems our series has no drift or trend, furthermore, the ADF rejects H0 of unit root when we do not include drift or trend.
# We are then dealing with no unit root. THUS, WE CANNOT USE VECM WITH THIS VARIABLE AS WE REQUIRE I(1).

test_unemployment <- CADFtest(Unemployment_ts, type='trend', criterion='BIC', max.lag.y=round(sqrt(length(Unemployment_ts))))
pander_display_test(test_unemployment)
test_unemployment <- CADFtest(Unemployment_ts, type='drift', criterion='BIC', max.lag.y=round(sqrt(length(Unemployment_ts))))
pander_display_test(test_unemployment)
test_unemployment <- CADFtest(Unemployment_ts, type='none', criterion='BIC', max.lag.y=round(sqrt(length(Unemployment_ts))))
pander_display_test(test_unemployment)
# We cannot reject H0 with a trend at 10%, so either we have a random walk with a stochastic trend, or simple non-stationary process.

### 2.2.2 Seasonality (We will just regress our TS against Monthly dummies to get rid of the seasonality).
par(mfrow=c(3,1))
monthplot(Prices_ts_log, main='Log CPI Seasonality', xlab='', ylab='', label=month.abb)
monthplot(Unemployment_ts, main='Unemployment Rate Seasonality', xlab='', ylab='', label=month.abb)
monthplot(Rates_ts, main='Interest Rates Seasonality', xlab='', ylab='', label=month.abb)
par(mfrow=c(1,1))

Prices_ts_log <- deseason(Prices_ts_log)
Unemployment_ts <- deseason(Unemployment_ts)
Rates_ts <- deseason(Rates_ts)

##  2.3 Cointegration
par(mfrow=c(2,2))
par(mar=c(3,4,2,1), oma=c(0,1,1,0))

logData <- cbind(Prices_ts_log, Unemployment_ts)
colnames(logData) <- c('Log Prices','Unemployment')

### 2.3.1 Checking order of the vector
auto_VAR <- VARselect(logData ,lag.max=10, type='const')
auto_VAR_order <- auto_VAR$selection['SC(n)']


### 2.3.2 Checking for Cointegrating equation based on proposed order (max 2 equations)
trace_test<-ca.jo(logData, type="trace",K=auto_VAR_order,ecdet="const",spec="transitory")
summary(trace_test)
maxeigen_test<-ca.jo(logData,type="eigen",K=auto_VAR_order,ecdet="const",spec="transitory")
summary(maxeigen_test)
# We find that there is one cointegrating equation.

##  2.4 Modelization
# Vector Error Correcting Model
VECM<-cajorls(trace_test,r=1)
VECM_res_log_prices <- ts(VECM$rlm$residuals[,1], start=c(2000,1), frequency=12)
residual_plots(VECM_res_log_prices,'VECM logPrices', lag=48)
VECM_res_log_unemployment <- ts(VECM$rlm$residuals[,2], start=c(2000,1), frequency=12)
residual_plots(VECM_res_log_unemployment,'VECM Unemployment', lag=48)

##  2.5 Forecast
par(mfrow=c(2,1))
par(mar=c(3,4,2,1), oma=c(1,1,1,1))

train_index <- round(nrow(logData))*0.85
train_series <- window(logData, end=c(2021,10))
test_series <- window(logData, start=c(2021,11))

auto_VAR_train <- VARselect(train_series ,lag.max=10, type='const')
auto_VAR_order_train <- auto_VAR_train$selection['SC(n)']
trace_test_train <- ca.jo(train_series, type="trace",K=auto_VAR_order_train,ecdet="const",spec="transitory")
fit_var <- vec2var(trace_test_train,r=1)
myforecast <- predict(fit_var,n.ahead=nrow(test_series))
names(myforecast$fcst) <- c('Log Prices','Unemployment')

for (varname in names(myforecast$fcst)){
  actual <- test_series[,varname]
  serie <- myforecast$fcst[[varname]]
  prediction <- ts(serie[,1], frequency=12, start=c(2021,11))
  upper <- ts(serie[,2], frequency=12, start=c(2021,11))
  lower <- ts(serie[,3], frequency=12, start=c(2021,11))
  titulo <- paste(varname,'Prediction from November 2021 to August 2025')
  plot.ts(actual, ylab=varname, xlab='', main=titulo, lty=1,lwd=2,col='blue',
          ylim=range(actual,lower, upper, prediction, na.rm = TRUE))
  lines(prediction,lty=1, lwd=2, col='red')
  lines(upper,lty=2, lwd=2, col='orange')
  lines(lower,lty=2, lwd=2, col='orange')
  legend('topleft',legend = c('Actual','Prediction','Bounds'), lty=c(1,1,2), lwd=c(2,2,2),
         col=c('blue','red','orange'), cex=0.7)
  grid()
}
par(mfrow=c(1,1))

##  2.6 Prediction validation
VECM_errors <- expanding_errors_multi(logData,VAR_order=2,coint_equations=1,horizon=1, plot=TRUE)
MSE_VECM <- round(colMeans(VECM_errors^2),3)
RMSE_VECM <- round(sqrt(colMeans(VECM_errors^2)),3)
MAE_VECM <- round(colMeans(abs(VECM_errors)),3)
MAPE_VECM <- MAPE_comp(logData,VECM_errors, multi=TRUE)
Error <- c('MSE','RMSE','MAE','MAPE')
df_VECM_errors <- as.data.frame(cbind(Error,rbind(MSE_VECM,RMSE_VECM,MAE_VECM,MAPE_VECM)))
rownames(df_VECM_errors) <- NULL
pander(df_VECM_errors, caption='Errors of Different series in VECM')

### 2.7 Testing for Equivalent models (Diebold-Mariano) for Log Prices: Univariate vs Multivariate Errors
Multivariate_Errors <- VECM_errors[,'Log Prices']
pander(dm.test(Multivariate_Errors,cpi_errors,h=1,power=1))
pander(dm.test(Multivariate_Errors,cpi_errors,h=1,power=2))

# The univariate model delivers larger Errors than our multivariate VECM, furthermore, after testing, the errors are statistically significant.

##  2.8 Impulse Response Functions
irf_var<-irf(fit_var,ortho=FALSE,boot=TRUE)
plot(irf_var)






